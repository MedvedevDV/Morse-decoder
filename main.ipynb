{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566be364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дивайс обучения: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "import librosa\n",
    "import Levenshtein\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ======== Настройки ========\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Дивайс обучения: {DEVICE}\")\n",
    "MORSEALP = \"АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#\"\n",
    "SAMPLE_RATE = 8000\n",
    "N_MELS = 64\n",
    "LAMBDA_REG = 1\n",
    "TOME_MASK_PARAM = 5\n",
    "FREQ_MASK_PARAM = 5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "def purified_signal_matrix(x_noisy:np.array, lambda_reg: int):\n",
    "    n = len(x_noisy)\n",
    "    \n",
    "    def loss_function(x):\n",
    "        # |x - x_noisy||2(Вторая норма) + λ *  sum(xi+1 - xi)\n",
    "        x_norm = x - x_noisy\n",
    "        second_norm = x_norm  @ x_norm.T\n",
    "        \n",
    "        reg = lambda_reg * np.sum(np.diff(x)**2)\n",
    "        \n",
    "        return second_norm + reg\n",
    "    \n",
    "    def gradient(x):\n",
    "        main_grad = 2 * (x - x_noisy)\n",
    "        \n",
    "        reg_grad = np.zeros(n)\n",
    "        reg_grad[:-1] += 2 * lambda_reg * (x[:-1] - x[1:])\n",
    "        reg_grad[1:] += 2 * lambda_reg * (x[1:] - x[:-1])\n",
    "        return main_grad + reg_grad\n",
    "    \n",
    "    x0 = x_noisy.copy()\n",
    "\n",
    "    res = minimize(loss_function, x0, method='L-BFGS-B', jac=gradient)\n",
    "    \n",
    "    return res.x\n",
    "\n",
    "\n",
    "def mel_augment(spec):\n",
    "    time_masking = torchaudio.transforms.TimeMasking(time_mask_param=TOME_MASK_PARAM) \n",
    "    freq_masking = torchaudio.transforms.FrequencyMasking(freq_mask_param=FREQ_MASK_PARAM)\n",
    "\n",
    "    spec_tensor = torch.from_numpy(spec) # torch.Size([64, 126])\n",
    "    augment = time_masking(spec_tensor)\n",
    "    augment = freq_masking(augment)\n",
    "\n",
    "    return augment.numpy()\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x = torch.stack([item[0] for item in batch])\n",
    "    y = pad_sequence([item[1] for item in batch], batch_first=True, padding_value=0)\n",
    "    y_len = torch.stack([item[2] for item in batch])\n",
    "    return x, y, y_len\n",
    "\n",
    "\n",
    "# ===== Dataset =====\n",
    "class MorseDataset(Dataset):\n",
    "    def __init__(self, audio_paths, messages, mode='train'):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.messages = messages\n",
    "        self.mode = mode\n",
    "        self.lambda_reg = LAMBDA_REG\n",
    "        self.sample_rate = SAMPLE_RATE\n",
    "        self.n_mels = N_MELS\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        message = self.messages[idx]\n",
    "\n",
    "        audio, sr = librosa.load(path, sr=self.sample_rate)\n",
    "        audio = purified_signal_matrix(audio, lambda_reg=self.lambda_reg)\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=self.n_mels)\n",
    "        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_spec = mel_augment(mel_spec)\n",
    "\n",
    "        std = mel_spec.std()\n",
    "        mel_spec = (mel_spec - mel_spec.mean()) / (std if std >= 1e-5 else 1e-5)\n",
    "        mel_spec = torch.FloatTensor(mel_spec).unsqueeze(0)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return mel_spec\n",
    "\n",
    "        label = torch.LongTensor([MORSEALP.find(c) + 1 for c in message if MORSEALP.find(c) != -1])\n",
    "        label_len = torch.LongTensor([len(label)])\n",
    "\n",
    "        return mel_spec, label, label_len\n",
    "\n",
    "\n",
    "# ===== Медель =====\n",
    "class MorseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, padding=1), nn.ReLU(), nn.BatchNorm2d(8), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 3, padding=1), nn.ReLU(), nn.BatchNorm2d(16), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.BatchNorm2d(32), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.BatchNorm2d(64), nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.conv_size = self.add_module\n",
    "\n",
    "        self.size = self.get_size()\n",
    "\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=self.size, hidden_size=128, num_layers=2,\n",
    "                           bidirectional=True, batch_first=True)\n",
    "        self.layer = nn.Linear(256, len(MORSEALP) + 1)\n",
    "\n",
    "    def get_size(self):\n",
    "        inp = torch.rand(1,1,64,128)\n",
    "        with torch.no_grad():\n",
    "            out = self.conv(inp)\n",
    "        \n",
    "        return out.size(1) * out.size(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = nn.Softmax(x)\n",
    "        b, c, h, t = x.size()\n",
    "        x = x.permute(0, 3, 2, 1).reshape(b, t, h * c)\n",
    "        x, h = self.rnn(x)\n",
    "        \n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "# === Обучение ===\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs):\n",
    "    model.to(DEVICE)\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for mel, labels, label_lens in train_loader:\n",
    "            mel, labels, label_lens = mel.to(DEVICE), labels.to(DEVICE), label_lens.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(mel)\n",
    "            T = output.size(1)\n",
    "            N = output.size(0)\n",
    "\n",
    "            input_lens = torch.full(size=(N,), fill_value=T, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "            output = output.permute(1, 0, 2)  #(N, T, C) -> (T, N, C)\n",
    "            flat_labels = torch.cat([labels[i, :label_lens[i]] for i in range(labels.size(0))])\n",
    "            if T < label_lens.max().item():\n",
    "                continue\n",
    "\n",
    "            loss = criterion(output, flat_labels, input_lens, label_lens.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_score = validate(model, val_loader)\n",
    "        print(f\"[Номер эпохи {epoch+1}]\\nЛосс за эпоху: {total_loss:.4f}\\nМетрика Лихтенштейна: {val_score:.4f}\")\n",
    "\n",
    "# ===== Валидация =====\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    distances = []\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, label_lens in val_loader:\n",
    "            mel = mel.to(DEVICE)\n",
    "            log_probs = model(mel).log_softmax(2)\n",
    "            decoded = decoder(log_probs)\n",
    "\n",
    "\n",
    "            targets = []\n",
    "            for i in range(labels.size(0)):\n",
    "                true_chars = [MORSEALP[i - 1] for i in labels[i][:label_lens[i]] if i > 0]\n",
    "                targets.append(\"\".join(true_chars))\n",
    "\n",
    "            # Расстояние Левенштейна\n",
    "            for t, p in zip(targets, decoded):\n",
    "                distance = Levenshtein.distance(t, p)\n",
    "                norm_dist = distance / max(len(t), 1)\n",
    "                distances.append(norm_dist)\n",
    "\n",
    "    mean_distance = np.mean(distances)\n",
    "    return mean_distance\n",
    "\n",
    "# ===== Декодер =====\n",
    "def decoder(log_mass):\n",
    "    preds = torch.argmax(log_mass, dim=2).cpu().numpy()\n",
    "    decoded = []\n",
    "    for pred in preds:\n",
    "        prev = -1\n",
    "        tokens = []\n",
    "        for p in pred:\n",
    "            if p != prev and p != 0:\n",
    "                tokens.append(MORSEALP[p - 1])\n",
    "            prev = p\n",
    "        decoded.append(\"\".join(tokens))\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e10064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== SETUP ========\n",
    "audio_dir = Path(os.getcwd()) / 'morse_dataset' / 'morse_dataset'\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "\n",
    "train_paths = [str(audio_dir / f\"{id_}\") for id_ in train_data['id']]\n",
    "val_paths = [str(audio_dir / f\"{id_}\") for id_ in val_data['id']]\n",
    "\n",
    "train_dataset = MorseDataset(train_paths, train_data['message'], mode='train')\n",
    "val_dataset = MorseDataset(val_paths, val_data['message'], mode='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MorseNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c733f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1_batch: tensor([[[-1.2132, -0.8879, -0.7573,  ..., -0.8810, -0.9047, -0.7022],\n",
      "         [-1.2625, -1.0439, -0.8171,  ..., -0.9026, -0.8088, -0.6537],\n",
      "         [-1.1210, -0.8837, -0.7991,  ..., -0.9774, -0.8377, -0.6510],\n",
      "         ...,\n",
      "         [-1.3600, -1.2079, -1.0604,  ..., -1.0058, -1.0339, -1.0167],\n",
      "         [-1.4935, -1.3644, -1.2531,  ..., -1.1216, -1.0721, -1.0919],\n",
      "         [-1.2546, -1.3095, -1.3762,  ..., -1.2617, -1.0958, -1.2398]]])\n",
      "tensor2_batch: tensor([18,  4, 26, 36, 42, 22])\n",
      "tensor3_batch: tensor([6])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset:\n",
    "    tensor1_batch, tensor2_batch, tensor3_batch = batch\n",
    "    print(\"tensor1_batch:\", tensor1_batch) \n",
    "    print(\"tensor2_batch:\", tensor2_batch)  \n",
    "    print(\"tensor3_batch:\", tensor3_batch)\n",
    "    #print(\"tensor3_batch:\", tensor4_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "179ae1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1_batch: tensor([[[[-1.0541, -0.7825, -0.9030,  ..., -1.0322, -0.8811, -0.8301],\n",
      "          [-1.2141, -0.9159, -0.9817,  ..., -0.9520, -0.8866, -0.9231],\n",
      "          [-1.3195, -0.9746, -0.9710,  ..., -1.0299, -1.0051, -0.9503],\n",
      "          ...,\n",
      "          [-1.5111, -1.4181, -1.2645,  ..., -1.1768, -0.9005, -0.9363],\n",
      "          [-1.8098, -1.6104, -1.3758,  ..., -1.2394, -0.9458, -0.9515],\n",
      "          [-1.7699, -1.6016, -1.4929,  ..., -1.4902, -1.1644, -0.9715]]],\n",
      "\n",
      "\n",
      "        [[[-1.1919, -0.9199, -0.8436,  ..., -0.5418, -0.5759, -0.2558],\n",
      "          [-1.0464, -0.7832, -0.7768,  ..., -0.4769, -0.5402, -0.2700],\n",
      "          [-1.0556, -0.8439, -0.7895,  ..., -0.4651, -0.4730, -0.2705],\n",
      "          ...,\n",
      "          [-1.4193, -1.2527, -0.9879,  ..., -1.2731, -1.1959, -0.9471],\n",
      "          [-1.7506, -1.4554, -1.2752,  ..., -1.4613, -1.2385, -0.9420],\n",
      "          [-2.0344, -1.5516, -1.3191,  ..., -1.5833, -1.2439, -0.9166]]],\n",
      "\n",
      "\n",
      "        [[[-1.7822, -1.5881, -1.5404,  ..., -1.3062, -1.2927, -1.3855],\n",
      "          [-1.6722, -1.4462, -1.3843,  ..., -1.2054, -1.1875, -1.1284],\n",
      "          [-1.5953, -1.2484, -1.2447,  ..., -1.3284, -1.1858, -1.0407],\n",
      "          ...,\n",
      "          [-1.9345, -1.9345, -1.9345,  ..., -1.9345, -1.3266, -1.0268],\n",
      "          [-1.9345, -1.9345, -1.9345,  ..., -1.9345, -1.3265, -1.0264],\n",
      "          [-1.9345, -1.9345, -1.9345,  ..., -1.9345, -1.2982, -0.9988]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1146, -0.9999, -1.1266,  ..., -0.6159, -0.8422, -0.9532],\n",
      "          [-1.0198, -0.9007, -0.9795,  ..., -0.6011, -0.7338, -0.7607],\n",
      "          [-0.8263, -0.6461, -0.6172,  ..., -0.5657, -0.5814, -0.6273],\n",
      "          ...,\n",
      "          [-1.6539, -1.6539, -1.6539,  ..., -1.6539, -1.3372, -1.0585],\n",
      "          [-1.6539, -1.6539, -1.6539,  ..., -1.6539, -1.3393, -1.0602],\n",
      "          [-1.6539, -1.6539, -1.6539,  ..., -1.6539, -1.3145, -1.0361]]],\n",
      "\n",
      "\n",
      "        [[[-0.9668, -0.7318, -0.7785,  ..., -0.6649, -0.8237, -0.9606],\n",
      "          [-0.8740, -0.6581, -0.7781,  ..., -0.6726, -0.6878, -0.7944],\n",
      "          [-1.0554, -0.6522, -0.6664,  ..., -0.5596, -0.7024, -0.7812],\n",
      "          ...,\n",
      "          [-1.6723, -1.4933, -1.5288,  ..., -1.3785, -1.3826, -1.4904],\n",
      "          [-1.9749, -1.5751, -1.5322,  ..., -1.7830, -1.6177, -1.6536],\n",
      "          [-2.0115, -1.6120, -1.5257,  ..., -1.7716, -1.6861, -1.8349]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0861,  0.2314,  0.1882,  ...,  0.1631,  0.0133, -0.0414],\n",
      "          [ 0.0665,  0.3368,  0.3188,  ...,  0.1131,  0.0963,  0.0359],\n",
      "          [ 0.3544,  0.5766,  0.5872,  ...,  0.3762,  0.3517,  0.3056],\n",
      "          ...,\n",
      "          [-1.9577, -1.9300, -2.0876,  ..., -1.8351, -1.7514, -1.8927],\n",
      "          [-1.9468, -1.8331, -1.9599,  ..., -1.9645, -1.7786, -1.8751],\n",
      "          [-1.8988, -1.7484, -1.7592,  ..., -1.7781, -1.7349, -1.9132]]]])\n",
      "tensor2_batch: tensor([[26, 11, 44, 38, 27, 34, 31,  0,  0,  0,  0,  0],\n",
      "        [35, 24, 34, 25, 17, 34, 22,  1,  2,  0,  0,  0],\n",
      "        [25, 14,  5, 39, 35, 27, 21,  4,  0,  0,  0,  0],\n",
      "        [31, 14, 21, 26,  3, 42, 19, 13, 32,  0,  0,  0],\n",
      "        [ 1,  9, 41,  9, 14,  5, 44,  0,  0,  0,  0,  0],\n",
      "        [ 2, 25, 40, 19,  9, 41, 45, 21,  0,  0,  0,  0],\n",
      "        [22, 13,  6,  4, 29, 29, 42,  0,  0,  0,  0,  0],\n",
      "        [39, 39, 27, 39,  3, 29, 39, 45, 14,  0,  0,  0],\n",
      "        [30, 30, 18, 39, 31, 38, 18, 29, 19, 42, 10, 19],\n",
      "        [40,  9, 19, 36, 34, 25, 43, 17, 24, 43,  0,  0],\n",
      "        [16,  8, 42, 18, 12, 29, 12, 12,  0,  0,  0,  0],\n",
      "        [30, 33, 17, 27, 42, 21, 11, 40,  0,  0,  0,  0],\n",
      "        [14, 37, 39, 24, 12, 11, 28,  0,  0,  0,  0,  0],\n",
      "        [25, 33, 44,  1, 33,  6, 15, 36, 29, 30,  6,  0],\n",
      "        [39,  1, 43, 37, 16, 29, 42,  0,  0,  0,  0,  0],\n",
      "        [35, 11, 27, 24, 25, 24,  5, 40,  0,  0,  0,  0]])\n",
      "tensor3_batch: tensor([[ 7],\n",
      "        [ 9],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [12],\n",
      "        [10],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [11],\n",
      "        [ 7],\n",
      "        [ 8]])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    tensor1_batch, tensor2_batch, tensor3_batch = batch\n",
    "    print(\"tensor1_batch:\", tensor1_batch) \n",
    "    print(\"tensor2_batch:\", tensor2_batch)  \n",
    "    print(\"tensor3_batch:\", tensor3_batch)\n",
    "    #print(\"tensor3_batch:\", tensor4_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94090326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 1/10 [07:03<1:03:29, 423.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 1]\n",
      "Лосс за эпоху: 5403.5642\n",
      "Метрика Лихтенштейна: 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 2/10 [12:25<48:31, 363.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 2]\n",
      "Лосс за эпоху: 4341.7236\n",
      "Метрика Лихтенштейна: 0.7018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 3/10 [18:06<41:14, 353.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 3]\n",
      "Лосс за эпоху: 3504.0994\n",
      "Метрика Лихтенштейна: 0.5685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 4/10 [22:18<31:19, 313.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 4]\n",
      "Лосс за эпоху: 3014.3972\n",
      "Метрика Лихтенштейна: 0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 5/10 [26:30<24:16, 291.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 5]\n",
      "Лосс за эпоху: 2749.2774\n",
      "Метрика Лихтенштейна: 0.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 6/10 [30:34<18:20, 275.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 6]\n",
      "Лосс за эпоху: 2561.2326\n",
      "Метрика Лихтенштейна: 0.4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 7/10 [34:46<13:22, 267.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 7]\n",
      "Лосс за эпоху: 2414.6891\n",
      "Метрика Лихтенштейна: 0.4652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 8/10 [38:59<08:46, 263.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 8]\n",
      "Лосс за эпоху: 2302.3685\n",
      "Метрика Лихтенштейна: 0.4450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 9/10 [43:11<04:19, 259.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 9]\n",
      "Лосс за эпоху: 2207.8196\n",
      "Метрика Лихтенштейна: 0.4503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [47:23<00:00, 284.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Номер эпохи 10]\n",
      "Лосс за эпоху: 2124.2111\n",
      "Метрика Лихтенштейна: 0.4262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer, criterion, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c47159af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    max_len = max([x[0].shape[2] for x in batch])\n",
    "\n",
    "    inputs = []\n",
    "    \n",
    "    for x in batch:\n",
    "        pad_amount = max_len - x[0].shape[2]\n",
    "        padded = torch.nn.functional.pad(x[0], (0, pad_amount), \"constant\", 0)\n",
    "        inputs.append(padded)\n",
    "    \n",
    "    inputs = torch.stack(inputs)\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58393e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30004.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30005.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>34996.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>34997.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>34998.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>34999.opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>35000.opus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id\n",
       "0     30001.opus\n",
       "1     30002.opus\n",
       "2     30003.opus\n",
       "3     30004.opus\n",
       "4     30005.opus\n",
       "...          ...\n",
       "4995  34996.opus\n",
       "4996  34997.opus\n",
       "4997  34998.opus\n",
       "4998  34999.opus\n",
       "4999  35000.opus\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_df = test_data.loc[0:4982]\n",
    "test_paths = str(audio_dir) + '\\\\' + test_df['id'].to_numpy()\n",
    "test_dataset = MorseDataset(test_paths, [\"\"] * len(test_df), mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4668fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1_batch: tensor([[[-0.7153, -0.3446, -0.4299,  ..., -0.5348, -0.4746, -0.6873],\n",
      "         [-0.4614, -0.2721, -0.3467,  ..., -0.4737, -0.4239, -0.8345],\n",
      "         [-0.5832, -0.2881, -0.2785,  ..., -0.3055, -0.3830, -0.7288],\n",
      "         ...,\n",
      "         [-1.7764, -1.7091, -1.7299,  ..., -1.6883, -1.5957, -1.7402],\n",
      "         [-1.8427, -1.7542, -1.8486,  ..., -1.7320, -1.6841, -1.9052],\n",
      "         [-1.9164, -1.7880, -1.8117,  ..., -1.7044, -1.7400, -1.8446]]])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_dataset:\n",
    "    tensor1_batch = batch\n",
    "    print(\"tensor1_batch:\", tensor1_batch) \n",
    "    #print(\"tensor3_batch:\", tensor4_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8c54fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1_batch: torch.Size([16, 1, 64, 126])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    tensor1_batch = batch\n",
    "    print(\"tensor1_batch:\", tensor1_batch.shape) \n",
    "    #print(\"tensor3_batch:\", tensor4_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9900a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA devices: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA devices: {torch.cuda.device_count()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91f7210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 28.89 MB\n",
      "Reserved: 136.00 MB\n",
      "Max allocated: 94.15 MB\n"
     ]
    }
   ],
   "source": [
    "def print_memory_stats():\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    print(f\"Reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")\n",
    "    print(f\"Max allocated: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")\n",
    "\n",
    "print_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41818ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Вывод: 100%|██████████| 312/312 [01:09<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты записаны в               id     message\n",
      "0     30001.opus    ЯЮ8 КЖБШ\n",
      "1     30002.opus     КЬ 0Ж 9\n",
      "2     30003.opus     #ЬЭ461Я\n",
      "3     30004.opus  ЖЖНЖ9РЫНЦ3\n",
      "4     30005.opus      ЩЦ3ЮЧЬ\n",
      "...          ...         ...\n",
      "4978  34979.opus     ЮНЮ7ИЪЫ\n",
      "4979  34980.opus   Ф7О634БТЫ\n",
      "4980  34981.opus    ЛГ88Е 6Ъ\n",
      "4981  34982.opus     П2БСА 8\n",
      "4982  34983.opus    ЗСА0СЫНВ\n",
      "\n",
      "[4983 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_9716\\3312359326.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['message'] = predic\n"
     ]
    }
   ],
   "source": [
    "def inference(model,df = test_df, test_loader = test_loader):\n",
    "    model.eval()\n",
    "    predic = []\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(test_loader, desc=\"Вывод\"):\n",
    "            batch = batch.to(DEVICE)\n",
    "            log_probs = model(batch).log_softmax(2)\n",
    "            decoded = decoder(log_probs)\n",
    "            predic.extend(decoded)\n",
    "\n",
    "    df['message'] = predic\n",
    "    # output_path = output_csv_path or test_csv\n",
    "    # test_df.to_csv(output_path, index=False)\n",
    "    print(f\"Результаты записаны в {df}\")\n",
    "\n",
    "inference(model, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5db270",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('filename.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
